{"cells":[{"cell_type":"markdown","metadata":{"id":"7com28W55pHk"},"source":["# Nutrition Image Analysis using CNN"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4528,"status":"ok","timestamp":1668857624672,"user":{"displayName":"Nitharsana S","userId":"11176970098266768969"},"user_tz":-330},"id":"V6Y6b4CLT82R","outputId":"8fd99853-50a8-4d18-cce5-406eb72f27b4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":74},"executionInfo":{"elapsed":12428,"status":"ok","timestamp":1668752196682,"user":{"displayName":"Sathiya Rupa","userId":"15061982909484360018"},"user_tz":-330},"id":"cjAnJqW_1Xyu","outputId":"5b7ca7ab-962e-4358-b68f-fb66b62f762c"},"outputs":[{"data":{"text/html":["\n","     <input type=\"file\" id=\"files-13a5c5db-0cd6-4d99-9991-1fe1f18cefcc\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-13a5c5db-0cd6-4d99-9991-1fe1f18cefcc\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Saving list - Sheet1.csv to list - Sheet1.csv\n"]}],"source":["from google.colab import files\n","uploaded = files.upload()"]},{"cell_type":"markdown","metadata":{"id":"whbZ5Uw35pHw"},"source":["### Importing Neccessary Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"60eg6zmo5pHx"},"outputs":[],"source":["#import keras libraries\n","import numpy as np\n","import tensorflow\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras import layers\n","from keras.layers import Dense\n","from keras.layers import Conv2D\n","from keras.layers import MaxPooling2D,Dropout\n","from keras.layers import Flatten\n","from keras.preprocessing.image import ImageDataGenerator"]},{"cell_type":"markdown","metadata":{"id":"ztVS3vjfw6M0"},"source":["# Saving Dataset.zip to Dataset.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":673,"status":"ok","timestamp":1668752481563,"user":{"displayName":"Sathiya Rupa","userId":"15061982909484360018"},"user_tz":-330},"id":"mjE8UM27xPnP","outputId":"0e3ab385-3abf-42b0-ad0f-21ccf300cdf6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Archive:  /content/Dataset-20221118T061955Z-001.zip\n","  End-of-central-directory signature not found.  Either this file is not\n","  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n","  latter case the central directory and zipfile comment will be found on\n","  the last disk(s) of this archive.\n","unzip:  cannot find zipfile directory in one of /content/Dataset-20221118T061955Z-001.zip or\n","        /content/Dataset-20221118T061955Z-001.zip.zip, and cannot find /content/Dataset-20221118T061955Z-001.zip.ZIP, period.\n"]}],"source":["!unzip '/content/Dataset-20221118T061955Z-001.zip' "]},{"cell_type":"markdown","metadata":{"id":"vnVt93M05pH0"},"source":["### Image Data Agumentation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-VLZKCTd5pH1"},"outputs":[],"source":["#setting parameter for Image Data agumentation to the training data\n","train_datagen = ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\n","#Image Data agumentation to the testing data\n","test_datagen=ImageDataGenerator(rescale=1./255)"]},{"cell_type":"markdown","metadata":{"id":"kpsHveuq5pH4"},"source":["### Loading our data and performing data agumentation"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":397},"id":"8Hkc9ffd5pH5","outputId":"c6b3117f-abfe-4860-8117-bc1bcd22ebd6","executionInfo":{"status":"error","timestamp":1668857555411,"user_tz":-330,"elapsed":22,"user":{"displayName":"Nitharsana S","userId":"11176970098266768969"}}},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-3ba8fc531815>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m x_train = train_datagen.flow_from_directory(\n\u001b[1;32m      3\u001b[0m     \u001b[0;34mr'/content/MyDrive/Colab_Notebooks/Dataset/TRAIN_SET'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     target_size=(64, 64),batch_size=5,color_mode='rgb',class_mode='sparse')\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#performing data agumentation to test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m x_test = test_datagen.flow_from_directory(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m   1485\u001b[0m         \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m         \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1487\u001b[0;31m         dtype=self.dtype)\n\u001b[0m\u001b[1;32m   1488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1489\u001b[0m   def flow_from_dataframe(self,\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[1;32m    505\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m       \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m           \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/MyDrive/Colab_Notebooks/Dataset/TRAIN_SET'"]}],"source":["#performing data agumentation to train data\n","x_train = train_datagen.flow_from_directory(\n","    r'/content/MyDrive/Colab_Notebooks/Dataset/TRAIN_SET',\n","    target_size=(64, 64),batch_size=5,color_mode='rgb',class_mode='sparse')\n","#performing data agumentation to test data\n","x_test = test_datagen.flow_from_directory(\n","    r'/content/MyDrive/Colab_Notebooks/Dataset/TEST_SET',\n","    target_size=(64, 64),batch_size=5,color_mode='rgb',class_mode='sparse') "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"szwYFmls5pH8"},"outputs":[],"source":["print(x_train.class_indices)#checking the number of classes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8SliKn605pH-"},"outputs":[],"source":["print(x_test.class_indices)#checking the number of classes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yWWDoRDw5pIA"},"outputs":[],"source":["from collections import Counter as c\n","c(x_train .labels)"]},{"cell_type":"markdown","metadata":{"id":"l3R_JW4b5pIC"},"source":["MODEL SUMMARY\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eejmbWX75pID"},"outputs":[],"source":["# Initializing the CNN\n","classifier = Sequential()\n","\n","# First convolution layer and pooling\n","classifier.add(Conv2D(32, (3, 3), input_shape=(64, 64, 3), activation='relu'))\n","classifier.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","# Second convolution layer and pooling\n","classifier.add(Conv2D(32, (3, 3), activation='relu'))\n","\n","# input_shape is going to be the pooled feature maps from the previous convolution layer\n","classifier.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","# Flattening the layers\n","classifier.add(Flatten())\n","\n","# Adding a fully connected layer\n","classifier.add(Dense(units=128, activation='relu'))\n","classifier.add(Dense(units=5, activation='softmax')) # softmax for more than 2\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QNCisXGE5pIE","colab":{"base_uri":"https://localhost:8080/","height":165},"executionInfo":{"status":"error","timestamp":1668856848774,"user_tz":-330,"elapsed":391,"user":{"displayName":"Nitharsana S","userId":"11176970098266768969"}},"outputId":"57e95eb3-6682-487d-8529-c523a16436d9"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-caeaf34c56a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#summary of our model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'classifier' is not defined"]}],"source":["classifier.summary()#summary of our model"]},{"cell_type":"markdown","metadata":{"id":"VTpQ5NR95pIF"},"source":["### Compiling the model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L0sf79GD5pIH"},"outputs":[],"source":["# Compiling the CNN\n","# categorical_crossentropy for more than 2\n","classifier.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy']) "]},{"cell_type":"markdown","metadata":{"id":"s6CAbE5c5pIL"},"source":["## Fitting the model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"l8JLV16x5pIM","scrolled":true,"outputId":"947701f4-5f12-4dd2-cad7-89c07b6699d1"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  This is separate from the ipykernel package so we can avoid doing imports until\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","526/526 [==============================] - 2406s 5s/step - loss: 0.1462 - accuracy: 0.9494 - val_loss: 3.2437 - val_accuracy: 0.5826\n","Epoch 2/20\n","526/526 [==============================] - 13s 24ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.9626 - val_accuracy: 0.5833\n","Epoch 3/20\n","526/526 [==============================] - 13s 26ms/step - loss: 0.0284 - accuracy: 0.9920 - val_loss: 4.0735 - val_accuracy: 0.5775\n","Epoch 4/20\n","526/526 [==============================] - 13s 24ms/step - loss: 1.4968e-04 - accuracy: 1.0000 - val_loss: 4.2227 - val_accuracy: 0.5935\n","Epoch 5/20\n","526/526 [==============================] - 13s 24ms/step - loss: 0.0413 - accuracy: 0.9893 - val_loss: 2.6469 - val_accuracy: 0.6797\n","Epoch 6/20\n","526/526 [==============================] - 13s 24ms/step - loss: 1.9354e-04 - accuracy: 1.0000 - val_loss: 3.1133 - val_accuracy: 0.6638\n","Epoch 7/20\n","526/526 [==============================] - 12s 24ms/step - loss: 7.8020e-05 - accuracy: 1.0000 - val_loss: 3.2678 - val_accuracy: 0.6609\n","Epoch 8/20\n","526/526 [==============================] - 14s 27ms/step - loss: 8.0794e-05 - accuracy: 1.0000 - val_loss: 3.4886 - val_accuracy: 0.6587\n","Epoch 9/20\n","526/526 [==============================] - 13s 25ms/step - loss: 2.5493e-05 - accuracy: 1.0000 - val_loss: 3.4794 - val_accuracy: 0.6681\n","Epoch 10/20\n","526/526 [==============================] - 13s 24ms/step - loss: 2.5018e-05 - accuracy: 1.0000 - val_loss: 3.5409 - val_accuracy: 0.6725\n","Epoch 11/20\n","526/526 [==============================] - 13s 24ms/step - loss: 1.1998e-05 - accuracy: 1.0000 - val_loss: 3.6840 - val_accuracy: 0.6674\n","Epoch 12/20\n","526/526 [==============================] - 13s 24ms/step - loss: 6.5817e-06 - accuracy: 1.0000 - val_loss: 3.7469 - val_accuracy: 0.6645\n","Epoch 13/20\n","526/526 [==============================] - 13s 25ms/step - loss: 7.4493e-06 - accuracy: 1.0000 - val_loss: 3.8639 - val_accuracy: 0.6580\n","Epoch 14/20\n","526/526 [==============================] - 13s 25ms/step - loss: 4.5897e-06 - accuracy: 1.0000 - val_loss: 3.9180 - val_accuracy: 0.6645\n","Epoch 15/20\n","526/526 [==============================] - 13s 24ms/step - loss: 3.1619e-06 - accuracy: 1.0000 - val_loss: 4.0008 - val_accuracy: 0.6623\n","Epoch 16/20\n","526/526 [==============================] - 13s 24ms/step - loss: 3.2284e-06 - accuracy: 1.0000 - val_loss: 3.9647 - val_accuracy: 0.6732\n","Epoch 17/20\n","526/526 [==============================] - 13s 24ms/step - loss: 1.7736e-06 - accuracy: 1.0000 - val_loss: 4.0060 - val_accuracy: 0.6696\n","Epoch 18/20\n","526/526 [==============================] - 13s 24ms/step - loss: 1.2016e-06 - accuracy: 1.0000 - val_loss: 4.0262 - val_accuracy: 0.6739\n","Epoch 19/20\n","526/526 [==============================] - 13s 25ms/step - loss: 8.7919e-07 - accuracy: 1.0000 - val_loss: 4.1578 - val_accuracy: 0.6659\n","Epoch 20/20\n","526/526 [==============================] - 12s 24ms/step - loss: 8.1175e-07 - accuracy: 1.0000 - val_loss: 4.0974 - val_accuracy: 0.6703\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x7f86ab416b90>"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["classifier.fit_generator(\n","        generator=x_train,steps_per_epoch = len(x_train),\n","        epochs=20, validation_data=x_test,validation_steps = len(x_test))# No of images in test set"]},{"cell_type":"markdown","metadata":{"id":"icM7Nuc35pIO"},"source":["### Saving our model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qAJYdsrl5pIQ"},"outputs":[],"source":["# Save the model\n","classifier.save('fruit.h5')"]},{"cell_type":"markdown","metadata":{"id":"wnKeLh5m5pIR"},"source":["### Predicting our results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3tJkyuyz5pIR"},"outputs":[],"source":["from tensorflow.keras.models import load_model\n","from keras.preprocessing import image\n","from tensorflow.keras.preprocessing import image\n","model = load_model(\"fruit.h5\") #loading the model for testing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lSQ6tnsR5pIc"},"outputs":[],"source":["img = tensorflow.keras.utils.load_img(r\"drive/My Drive/Sample_Images/Test_Image1.jpg\",grayscale=False,target_size= (64,64))#loading of the image\n","x = image.img_to_array(img)#image to array\n","x = np.expand_dims(x,axis = 0)#changing the shape\n","#pred = (model.predict(x) > 0.5).astype(\"int32\")#predicting the classes\n","pred = np.argmax(model.predict(x), axis=-1)\n","pred"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EazH0bQ05pIc"},"outputs":[],"source":["index=['APPLES', 'BANANA', 'ORANGE','PINEAPPLE','WATERMELON']\n","result=str(index[pred[0]])\n","result"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"psfuX7AC5pIe"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"}},"nbformat":4,"nbformat_minor":0}